     1→# LogFlow: Master Build Prompt for Agent
     2→
     3→## Mission
     4→
     5→Build a production-grade, high-performance data ingestion and analytics library in Go that can **stream any data format and output analysis-ready Parquet/Iceberg**, with pluggable interfaces for auth, catalog, storage, and scheduling.
     6→
     7→---
     8→
     9→## Context & Prior Work
    10→
    11→### What Already Exists (in `/Users/namanagarwal/logpro/pkg/ingest/`)
    12→
    13→```
    14→pkg/ingest/
    15→├── detect.go         (780 lines)  - Format/delimiter/encoding detection
    16→├── heuristics.go     (707 lines)  - Source buckets, decision table, adaptive tuning
    17→├── pipeline.go       (450 lines)  - Unified pipeline with concurrency control
    18→├── fast_path.go      (355 lines)  - DuckDB native processing
    19→├── robust_path.go    (830 lines)  - Go streaming with error recovery
    20→├── quality.go        (612 lines)  - Checksum, entropy, cardinality (HyperLogLog)
    21→├── ingest.go         (357 lines)  - Engine API
    22→└── benchmark_test.go (600 lines)  - Tests and benchmarks
    23→```
    24→
    25→**Current Performance**: 933K rows/sec, 106 MB/sec, EXCELLENT grade
    26→
    27→### Key Documents to Reference
    28→- `PLATFORM_ARCHITECTURE.md` - Full multi-dimensional architecture
    29→- `INGESTION_PLAN.md` - Detailed integration plan
    30→- `INTEGRATION_PLAN.md` - Module-level refactoring plan
    31→
    32→---
    33→
    34→## Architecture Principles
    35→
    36→### 1. Core vs Pluggable Separation
    37→
    38→```
    39→┌─────────────────────────────────────────────────────────────────────────┐
    40→│                         PLUGGABLE (Interfaces)                           │
    41→│   Auth │ Catalog │ Storage │ Scheduler │ Alerting │ Metrics             │
    42→└────────────────────────────────┬────────────────────────────────────────┘
    43→                                 │ plug into
    44→┌────────────────────────────────▼────────────────────────────────────────┐
    45→│                         CORE ENGINE (We Build)                           │
    46→│                                                                          │
    47→│   ANY FORMAT ──▶ DETECT ──▶ DECODE ──▶ VALIDATE ──▶ WRITE ──▶ QUERY    │
    48→│                                                                          │
    49→│   Inputs:  CSV, TSV, JSON, JSONL, XML, XES, Parquet, Avro, Excel, Logs  │
    50→│   Outputs: Parquet files, Iceberg tables, Delta tables, Arrow streams   │
    51→│   Query:   DuckDB-based SQL, Arrow Flight for streaming                 │
    52→│                                                                          │
    53→└─────────────────────────────────────────────────────────────────────────┘
    54→```
    55→
    56→### 2. The Three Layers
    57→
    58→| Layer | Responsibility | Key Interfaces |
    59→|-------|----------------|----------------|
    60→| **Ingest** | Stream any format → Arrow → Storage | `Source`, `Decoder`, `Sink` |
    61→| **Storage** | Manage tables, partitions, versioning | `Catalog`, `Table`, `ObjectStorage` |
    62→| **Query** | SQL analytics on stored data | `QueryEngine`, `ResultSet` |
    63→
    64→### 3. Heuristic-Driven Processing
    65→
    66→```
    67→Source Classification (by processing cost):
    68→├── Bucket 1 - Native (Parquet, ORC, Avro): ~500 MB/s, high concurrency
    69→├── Bucket 2 - Cheap (CSV, TSV, JSONL): ~150 MB/s, medium concurrency
    70→├── Bucket 3 - Medium (JSON, XML): ~50 MB/s, limited concurrency
    71→└── Bucket 4 - Expensive (Excel, PDF): ~10 MB/s, low concurrency
    72→
    73→Decision Flow:
    74→File → Detect Format → Classify Bucket → Select Strategy → Configure Heuristics → Execute
    75→```
    76→
    77→---
    78→
    79→## Complete Module Structure to Build
    80→
    81→```
    82→pkg/
    83→│
    84→├── ═══════════════════════════════════════════════════════════════════════
    85→│   INTERFACES (Users implement these to extend the system)
    86→├── ═══════════════════════════════════════════════════════════════════════
    87→│
    88→├── interfaces/
    89→│   ├── auth.go                 # Authenticator, Authorizer, Identity
    90→│   ├── catalog.go              # Catalog, Table, TableSpec
    91→│   ├── storage.go              # ObjectStorage, ObjectInfo
    92→│   ├── scheduler.go            # Scheduler, Job, JobSpec, JobStatus
    93→│   ├── metrics.go              # MetricsExporter, Gauge, Counter, Histogram
    94→│   ├── tracer.go               # Tracer, Span, SpanContext
    95→│   └── alerter.go              # Alerter, Alert, AlertLevel
    96→│
    97→├── ═══════════════════════════════════════════════════════════════════════
    98→│   CORE - Ingest Layer (Stream anything to Arrow)
    99→├── ═══════════════════════════════════════════════════════════════════════
   100→│
   101→├── ingest/
   102→│   │
   103→│   ├── core/                   # Core abstractions
   104→│   │   ├── source.go           # Source interface: Location(), Open(), Metadata()
   105→│   │   ├── decoder.go          # Decoder interface: Decode() -> chan RecordBatch
   106→│   │   ├── sink.go             # Sink interface: Write(RecordBatch), Close()
   107→│   │   ├── batch.go            # RecordBatch wrapper with metadata
   108→│   │   └── options.go          # IngestOptions, DecodeOptions, SinkOptions
   109→│   │
   110→│   ├── sources/                # Source implementations
   111→│   │   ├── file.go             # Local file source
   112→│   │   ├── glob.go             # Glob pattern source (multiple files)
   113→│   │   ├── http.go             # HTTP/HTTPS URL source
   114→│   │   ├── stream.go           # io.Reader wrapper
   115→│   │   └── memory.go           # In-memory bytes source (for testing)
   116→│   │
   117→│   ├── detect/                 # Format detection (REFACTOR from detect.go)
   118→│   │   ├── detector.go         # Main Detector struct
   119→│   │   ├── format.go           # Format enum and detection
   120→│   │   ├── encoding.go         # Character encoding detection
   121→│   │   ├── delimiter.go        # CSV delimiter detection
   122→│   │   ├── magic.go            # Magic byte detection
   123→│   │   └── quality.go          # Data quality indicators
   124→│   │
   125→│   ├── decoders/               # Format decoders (all implement Decoder interface)
   126→│   │   ├── registry.go         # Decoder registry with format routing
   127→│   │   ├── duckdb.go           # DuckDB-based decoder (REFACTOR from fast_path.go)
   128→│   │   ├── csv.go              # Streaming CSV decoder (REFACTOR from robust_path.go)
   129→│   │   ├── json.go             # JSON/JSONL decoder
   130→│   │   ├── xml.go              # XML decoder
   131→│   │   ├── xes.go              # XES process mining decoder
   132→│   │   ├── parquet.go          # Parquet pass-through decoder
   133→│   │   ├── avro.go             # Avro decoder
   134→│   │   ├── excel.go            # Excel decoder
   135→│   │   └── custom.go           # Custom decoder registration
   136→│   │
   137→│   ├── sinks/                  # Output sinks (all implement Sink interface)
   138→│   │   ├── parquet.go          # Parquet file sink
   139→│   │   ├── iceberg.go          # Iceberg table sink
   140→│   │   ├── delta.go            # Delta Lake sink
   141→│   │   ├── arrow_ipc.go        # Arrow IPC stream sink
   142→│   │   └── null.go             # Null sink (for benchmarking)
   143→│   │
   144→│   ├── schema/                 # Schema management
   145→│   │   ├── inference.go        # Infer schema from data samples
   146→│   │   ├── evolution.go        # Schema evolution (add/drop/rename columns)
   147→│   │   ├── policy.go           # Schema policies (strict, merge, evolve)
   148→│   │   ├── cache.go            # Schema caching (infer once, apply many)
   149→│   │   └── mapping.go          # Type mapping between formats
   150→│   │
   151→│   ├── quality/                # Data quality (REFACTOR from quality.go)
   152→│   │   ├── validator.go        # Streaming quality validator
   153→│   │   ├── checksum.go         # FNV-1a/xxHash checksums
   154→│   │   ├── entropy.go          # Shannon entropy calculation
   155→│   │   ├── cardinality.go      # HyperLogLog cardinality estimation
   156→│   │   ├── rules.go            # Validation rules (not null, range, pattern)
   157→│   │   └── report.go           # Quality report generation
   158→│   │
   159→│   ├── errors/                 # Error handling
   160→│   │   ├── policy.go           # Error policies (strict, permissive, quarantine)
   161→│   │   ├── handler.go          # Error handler with callbacks
   162→│   │   ├── quarantine.go       # Quarantine bad records to separate file
   163→│   │   └── recovery.go         # Error recovery strategies
   164→│   │
   165→│   ├── heuristics/             # Decision engine (REFACTOR from heuristics.go)
   166→│   │   ├── engine.go           # HeuristicEngine main struct
   167→│   │   ├── buckets.go          # Source bucket classification
   168→│   │   ├── decisions.go        # Decision table rules
   169→│   │   ├── adaptive.go         # Adaptive tuning from metrics
   170→│   │   └── config.go           # Heuristic configuration
   171→│   │
   172→│   ├── flow/                   # Flow control
   173→│   │   ├── backpressure.go     # Bounded queue with backpressure
   174→│   │   ├── concurrency.go      # Per-bucket concurrency limits
   175→│   │   ├── rate_limiter.go     # Optional rate limiting
   176→│   │   └── batch_accumulator.go # Accumulate records into batches
   177→│   │
   178→│   ├── pipeline.go             # Main Pipeline orchestrator (REFACTOR)
   179→│   ├── engine.go               # High-level Engine API
   180→│   └── config.go               # Unified configuration
   181→│
   182→├── ═══════════════════════════════════════════════════════════════════════
   183→│   CORE - Storage Layer (Table management)
   184→├── ═══════════════════════════════════════════════════════════════════════
   185→│
   186→├── storage/
   187→│   │
   188→│   ├── table/                  # Table abstraction
   189→│   │   ├── table.go            # Table interface implementation
   190→│   │   ├── schema.go           # Table schema operations
   191→│   │   ├── partitioning.go     # Partition strategies
   192→│   │   ├── statistics.go       # Table statistics
   193→│   │   └── snapshot.go         # Point-in-time snapshots
   194→│   │
   195→│   ├── catalog/                # Catalog implementations
   196→│   │   ├── interface.go        # Catalog interface (defined in interfaces/)
   197→│   │   ├── file.go             # Simple file-based catalog (DEFAULT)
   198→│   │   ├── memory.go           # In-memory catalog (for testing)
   199→│   │   └── sql.go              # SQL-based catalog (SQLite/Postgres)
   200→│   │
   201→│   ├── object/                 # Object storage implementations
   202→│   │   ├── interface.go        # ObjectStorage interface (in interfaces/)
   203→│   │   ├── local.go            # Local filesystem (DEFAULT)
   204→│   │   └── memory.go           # In-memory storage (for testing)
   205→│   │
   206→│   ├── layout/                 # File layout strategies
   207→│   │   ├── partitioner.go      # Partition files by columns
   208→│   │   ├── naming.go           # File naming conventions
   209→│   │   └── sizing.go           # Target file sizing
   210→│   │
   211→│   └── maintenance/            # Storage maintenance
   212→│       ├── compaction.go       # Compact small files
   213→│       ├── vacuum.go           # Remove old snapshots
   214→│       └── optimize.go         # Optimize layout (clustering)
   215→│
   216→├── ═══════════════════════════════════════════════════════════════════════
   217→│   CORE - Query Layer (SQL analytics)
   218→├── ═══════════════════════════════════════════════════════════════════════
   219→│
   220→├── query/
   221→│   │
   222→│   ├── engine/                 # Query execution
   223→│   │   ├── engine.go           # QueryEngine interface and DuckDB impl
   224→│   │   ├── context.go          # Query context (timeout, memory limit)
   225→│   │   ├── result.go           # QueryResult, ResultSet interfaces
   226→│   │   └── streaming.go        # Streaming result iteration
   227→│   │
   228→│   ├── sql/                    # SQL handling
   229→│   │   ├── parser.go           # SQL parsing (use sqlparser library)
   230→│   │   ├── validator.go        # SQL validation
   231→│   │   └── rewriter.go         # Query rewriting (add filters, etc.)
   232→│   │
   233→│   ├── cache/                  # Query caching
   234→│   │   ├── result_cache.go     # Cache query results
   235→│   │   ├── metadata_cache.go   # Cache table metadata
   236→│   │   └── invalidation.go     # Cache invalidation strategies
   237→│   │
   238→│   ├── flight/                 # Arrow Flight server
   239→│   │   ├── server.go           # Flight server implementation
   240→│   │   ├── handlers.go         # GetFlightInfo, DoGet, DoPut
   241→│   │   └── auth.go             # Flight authentication
   242→│   │
   243→│   └── semantic/               # Semantic layer (optional)
   244→│       ├── model.go            # Semantic model definition
   245→│       ├── dimension.go        # Dimension definitions
   246→│       ├── measure.go          # Measure definitions
   247→│       └── query_builder.go    # Build SQL from semantic queries
   248→│
   249→├── ═══════════════════════════════════════════════════════════════════════
   250→│   DEFAULTS - Simple implementations users can use out-of-box
   251→├── ═══════════════════════════════════════════════════════════════════════
   252→│
   253→├── defaults/
   254→│   ├── auth/
   255→│   │   ├── noop.go             # No auth (for local/dev)
   256→│   │   └── apikey.go           # Simple API key auth
   257→│   │
   258→│   ├── metrics/
   259→│   │   ├── noop.go             # No metrics
   260→│   │   └── log.go              # Log-based metrics
   261→│   │
   262→│   └── alerting/
   263→│       ├── noop.go             # No alerting
   264→│       └── log.go              # Log-based alerting
   265→│
   266→├── ═══════════════════════════════════════════════════════════════════════
   267→│   API - External interfaces
   268→├── ═══════════════════════════════════════════════════════════════════════
   269→│
   270→├── api/
   271→│   ├── rest/                   # REST API
   272→│   │   ├── server.go           # HTTP server setup
   273→│   │   ├── routes.go           # Route definitions
   274→│   │   ├── handlers/
   275→│   │   │   ├── ingest.go       # POST /v1/ingest
   276→│   │   │   ├── query.go        # POST /v1/query
   277→│   │   │   ├── tables.go       # CRUD /v1/tables
   278→│   │   │   └── health.go       # GET /health
   279→│   │   └── middleware/
   280→│   │       ├── auth.go         # Auth middleware (uses interfaces.Authenticator)
   281→│   │       ├── logging.go      # Request logging
   282→│   │       ├── recovery.go     # Panic recovery
   283→│   │       └── cors.go         # CORS handling
   284→│   │
   285→│   └── grpc/                   # gRPC API (optional, for high-perf)
   286→│       ├── proto/
   287→│       │   ├── ingest.proto
   288→│       │   └── query.proto
   289→│       └── server.go
   290→│
   291→├── ═══════════════════════════════════════════════════════════════════════
   292→│   CONFIG - Unified configuration
   293→├── ═══════════════════════════════════════════════════════════════════════
   294→│
   295→├── config/
   296→│   ├── config.go               # Main Config struct
   297→│   ├── defaults.go             # Default values
   298→│   ├── loader.go               # Load from file/env
   299→│   └── validation.go           # Config validation
   300→│
   301→├── ═══════════════════════════════════════════════════════════════════════
   302→│   TESTING - Test utilities
   303→├── ═══════════════════════════════════════════════════════════════════════
   304→│
   305→├── testing/
   306→│   ├── generators/
   307→│   │   ├── csv.go              # Generate test CSV
   308→│   │   ├── json.go             # Generate test JSON
   309→│   │   ├── noisy.go            # Generate noisy/dirty data
   310→│   │   └── xes.go              # Generate XES process mining data
   311→│   │
   312→│   ├── assertions/
   313→│   │   ├── schema.go           # Schema assertions
   314→│   │   ├── data.go             # Data assertions
   315→│   │   └── parquet.go          # Parquet file assertions
   316→│   │
   317→│   └── roundtrip/
   318→│       └── roundtrip.go        # Round-trip testing utilities
   319→│
   320→└── ═══════════════════════════════════════════════════════════════════════
   321→    PUBLIC API - Main entry points
   322→    ═══════════════════════════════════════════════════════════════════════
   323→
   324→├── logflow.go                  # Main package entry point
   325→└── doc.go                      # Package documentation
   326→```
   327→
   328→---
   329→
   330→## Interface Definitions (Critical - Build These First)
   331→
   332→### interfaces/auth.go
   333→```go
   334→package interfaces
   335→
   336→import "context"
   337→
   338→// Identity represents an authenticated user/service
   339→type Identity interface {
   340→    ID() string
   341→    Type() string // "user", "service", "api_key"
   342→    Tenant() string
   343→    Roles() []string
   344→    Attributes() map[string]string
   345→}
   346→
   347→// Authenticator validates credentials and returns identity
   348→type Authenticator interface {
   349→    // Authenticate validates the token and returns identity
   350→    Authenticate(ctx context.Context, token string) (Identity, error)
   351→
   352→    // Type returns the auth type (jwt, apikey, oauth, mtls)
   353→    Type() string
   354→}
   355→
   356→// Authorizer checks if identity can perform action
   357→type Authorizer interface {
   358→    // Authorize checks if identity can perform action on resource
   359→    Authorize(ctx context.Context, identity Identity, action string, resource string) (bool, error)
   360→
   361→    // AuthorizeData checks row/column level access
   362→    AuthorizeData(ctx context.Context, identity Identity, table string, columns []string, filter string) (allowed bool, appliedFilter string, err error)
   363→}
   364→
   365→// NoopAuthenticator allows all requests (for local/dev use)
   366→type NoopAuthenticator struct{}
   367→
   368→func (n *NoopAuthenticator) Authenticate(ctx context.Context, token string) (Identity, error) {
   369→    return &AnonymousIdentity{}, nil
   370→}
   371→
   372→func (n *NoopAuthenticator) Type() string { return "noop" }
   373→```
   374→
   375→### interfaces/catalog.go
   376→```go
   377→package interfaces
   378→
   379→import (
   380→    "context"
   381→    "github.com/apache/arrow/go/v14/arrow"
   382→)
   383→
   384→// Catalog manages table metadata
   385→type Catalog interface {
   386→    // Table operations
   387→    CreateTable(ctx context.Context, spec TableSpec) error
   388→    GetTable(ctx context.Context, database, table string) (Table, error)
   389→    ListTables(ctx context.Context, database string) ([]TableInfo, error)
   390→    DropTable(ctx context.Context, database, table string) error
   391→
   392→    // Database operations
   393→    CreateDatabase(ctx context.Context, name string) error
   394→    ListDatabases(ctx context.Context) ([]string, error)
   395→    DropDatabase(ctx context.Context, name string) error
   396→}
   397→
   398→// Table represents a logical table
   399→type Table interface {
   400→    // Metadata
   401→    Name() string
   402→    Database() string
   403→    Schema() *arrow.Schema
   404→    Location() string
   405→    Format() TableFormat
   406→    Partitioning() PartitionSpec
   407→    Properties() map[string]string
   408→
   409→    // Snapshots (for time travel)
   410→    CurrentSnapshot() Snapshot
   411→    Snapshots() []Snapshot
   412→    AsOf(version int64) (Table, error)
   413→    AsOfTime(timestamp int64) (Table, error)
   414→
   415→    // Files
   416→    DataFiles() []DataFile
   417→    ManifestFiles() []ManifestFile
   418→}
   419→
   420→// TableSpec defines a new table
   421→type TableSpec struct {
   422→    Database     string
   423→    Name         string
   424→    Schema       *arrow.Schema
   425→    Location     string
   426→    Format       TableFormat
   427→    Partitioning PartitionSpec
   428→    Properties   map[string]string
   429→}
   430→
   431→// TableFormat is the underlying format
   432→type TableFormat int
   433→
   434→const (
   435→    FormatParquet TableFormat = iota
   436→    FormatIceberg
   437→    FormatDelta
   438→    FormatHudi
   439→)
   440→```
   441→
   442→### interfaces/storage.go
   443→```go
   444→package interfaces
   445→
   446→import (
   447→    "context"
   448→    "io"
   449→)
   450→
   451→// ObjectStorage provides object storage operations
   452→type ObjectStorage interface {
   453→    // Basic operations
   454→    Put(ctx context.Context, path string, data io.Reader, opts PutOptions) error
   455→    Get(ctx context.Context, path string) (io.ReadCloser, error)
   456→    Delete(ctx context.Context, path string) error
   457→    Exists(ctx context.Context, path string) (bool, error)
   458→
   459→    // Listing
   460→    List(ctx context.Context, prefix string, opts ListOptions) ([]ObjectInfo, error)
   461→    ListPaginated(ctx context.Context, prefix string, opts ListOptions) ObjectIterator
   462→
   463→    // Metadata
   464→    Head(ctx context.Context, path string) (ObjectInfo, error)
   465→
   466→    // Bulk operations
   467→    DeleteMany(ctx context.Context, paths []string) error
   468→    Copy(ctx context.Context, src, dst string) error
   469→}
   470→
   471→// ObjectInfo contains object metadata
   472→type ObjectInfo struct {
   473→    Path         string
   474→    Size         int64
   475→    LastModified int64
   476→    ETag         string
   477→    ContentType  string
   478→    Metadata     map[string]string
   479→}
   480→
   481→// PutOptions for write operations
   482→type PutOptions struct {
   483→    ContentType string
   484→    Metadata    map[string]string
   485→}
   486→
   487→// ListOptions for listing operations
   488→type ListOptions struct {
   489→    MaxKeys   int
   490→    Delimiter string
   491→    StartAfter string
   492→}
   493→```
   494→
   495→### interfaces/scheduler.go
   496→```go
   497→package interfaces
   498→
   499→import (
   500→    "context"
   501→    "time"
   502→)
   503→
   504→// Scheduler manages job scheduling and execution
   505→type Scheduler interface {
   506→    // Job lifecycle
   507→    Submit(ctx context.Context, spec JobSpec) (JobID, error)
   508→    Cancel(ctx context.Context, id JobID) error
   509→    Get(ctx context.Context, id JobID) (Job, error)
   510→
   511→    // Listing
   512→    List(ctx context.Context, filter JobFilter) ([]Job, error)
   513→
   514→    // Scheduling
   515→    Schedule(ctx context.Context, spec JobSpec, schedule Schedule) (JobID, error)
   516→    Unschedule(ctx context.Context, id JobID) error
   517→}
   518→
   519→// JobSpec defines a job to run
   520→type JobSpec struct {
   521→    Name        string
   522→    Type        JobType
   523→    Config      map[string]interface{}
   524→    Priority    int
   525→    Timeout     time.Duration
   526→    Retries     int
   527→    DependsOn   []JobID
   528→}
   529→
   530→// JobType categorizes jobs
   531→type JobType string
   532→
   533→const (
   534→    JobTypeIngest     JobType = "ingest"
   535→    JobTypeTransform  JobType = "transform"
   536→    JobTypeExport     JobType = "export"
   537→    JobTypeCompaction JobType = "compaction"
   538→    JobTypeVacuum     JobType = "vacuum"
   539→)
   540→
   541→// Job represents a running or completed job
   542→type Job interface {
   543→    ID() JobID
   544→    Spec() JobSpec
   545→    Status() JobStatus
   546→    Progress() float64
   547→    StartedAt() time.Time
   548→    CompletedAt() time.Time
   549→    Error() error
   550→    Metrics() JobMetrics
   551→}
   552→
   553→// JobStatus is the job state
   554→type JobStatus string
   555→
   556→const (
   557→    JobStatusPending   JobStatus = "pending"
   558→    JobStatusRunning   JobStatus = "running"
   559→    JobStatusSucceeded JobStatus = "succeeded"
   560→    JobStatusFailed    JobStatus = "failed"
   561→    JobStatusCancelled JobStatus = "cancelled"
   562→)
   563→
   564→// Schedule defines when a job runs
   565→type Schedule struct {
   566→    Type       ScheduleType
   567→    Cron       string        // For cron type
   568→    Interval   time.Duration // For interval type
   569→    StartTime  time.Time
   570→    EndTime    time.Time
   571→    Timezone   string
   572→}
   573→
   574→// NoopScheduler runs jobs immediately (no scheduling)
   575→type NoopScheduler struct{}
   576→```
   577→
   578→### interfaces/metrics.go
   579→```go
   580→package interfaces
   581→
   582→// MetricsExporter exports metrics to a backend
   583→type MetricsExporter interface {
   584→    // Counters
   585→    Counter(name string, value int64, tags map[string]string)
   586→
   587→    // Gauges
   588→    Gauge(name string, value float64, tags map[string]string)
   589→
   590→    // Histograms
   591→    Histogram(name string, value float64, tags map[string]string)
   592→
   593→    // Timers
   594→    Timer(name string, duration int64, tags map[string]string)
   595→
   596→    // Flush any buffered metrics
   597→    Flush() error
   598→}
   599→
   600→// NoopMetrics discards all metrics
   601→type NoopMetrics struct{}
   602→```
   603→
   604→---
   605→
   606→## Core Abstractions (Build After Interfaces)
   607→
   608→### ingest/core/source.go
   609→```go
   610→package core
   611→
   612→import (
   613→    "context"
   614→    "io"
   615→)
   616→
   617→// Source represents a data source to ingest
   618→type Source interface {
   619→    // Identity
   620→    ID() string
   621→    Location() string
   622→
   623→    // Metadata
   624→    Format() Format
   625→    Size() int64
   626→    Metadata() map[string]string
   627→
   628→    // Reading
   629→    Open(ctx context.Context) (io.ReadCloser, error)
   630→    OpenSeekable(ctx context.Context) (io.ReadSeekCloser, error)
   631→}
   632→
   633→// Format identifies the data format
   634→type Format string
   635→
   636→const (
   637→    FormatUnknown Format = ""
   638→    FormatCSV     Format = "csv"
   639→    FormatTSV     Format = "tsv"
   640→    FormatJSON    Format = "json"
   641→    FormatJSONL   Format = "jsonl"
   642→    FormatXML     Format = "xml"
   643→    FormatXES     Format = "xes"
   644→    FormatParquet Format = "parquet"
   645→    FormatAvro    Format = "avro"
   646→    FormatORC     Format = "orc"
   647→    FormatExcel   Format = "xlsx"
   648→)
   649→```
   650→
   651→### ingest/core/decoder.go
   652→```go
   653→package core
   654→
   655→import (
   656→    "context"
   657→    "github.com/apache/arrow/go/v14/arrow"
   658→)
   659→
   660→// Decoder converts a source into Arrow RecordBatches
   661→type Decoder interface {
   662→    // Metadata
   663→    ID() string
   664→    SupportedFormats() []Format
   665→    CostHint() int // 1=cheap, 2=medium, 3=expensive
   666→
   667→    // Schema
   668→    InferSchema(ctx context.Context, source Source, opts InferOptions) (*arrow.Schema, error)
   669→
   670→    // Decoding
   671→    Decode(ctx context.Context, source Source, schema *arrow.Schema, opts DecodeOptions) (<-chan DecodedBatch, error)
   672→}
   673→
   674→// DecodedBatch is a RecordBatch with metadata
   675→type DecodedBatch struct {
   676→    Batch     arrow.Record
   677→    Index     int64      // Batch index
   678→    Offset    int64      // Byte offset in source
   679→    RowCount  int64      // Rows in this batch
   680→    Errors    []RowError // Errors during decoding
   681→    IsFinal   bool       // Last batch
   682→}
   683→
   684→// RowError represents an error for a specific row
   685→type RowError struct {
   686→    Row     int64
   687→    Column  string
   688→    Message string
   689→    Raw     []byte
   690→}
   691→
   692→// DecodeOptions configures decoding
   693→type DecodeOptions struct {
   694→    BatchSize       int
   695→    Schema          *arrow.Schema // If nil, infer
   696→    ErrorPolicy     ErrorPolicy
   697→    MaxErrors       int
   698→    OnError         func(RowError)
   699→    OnProgress      func(bytesRead, totalBytes int64)
   700→}
   701→
   702→// ErrorPolicy defines error handling
   703→type ErrorPolicy int
   704→
   705→const (
   706→    ErrorPolicyStrict     ErrorPolicy = iota // Abort on first error
   707→    ErrorPolicyPermissive                    // Skip bad rows
   708→    ErrorPolicyQuarantine                    // Write bad rows to separate file
   709→)
   710→```
   711→
   712→### ingest/core/sink.go
   713→```go
   714→package core
   715→
   716→import (
   717→    "context"
   718→    "github.com/apache/arrow/go/v14/arrow"
   719→)
   720→
   721→// Sink writes Arrow RecordBatches to a destination
   722→type Sink interface {
   723→    // Lifecycle
   724→    Open(ctx context.Context, schema *arrow.Schema, opts SinkOptions) error
   725→    Write(ctx context.Context, batch arrow.Record) error
   726→    Flush(ctx context.Context) error
   727→    Close(ctx context.Context) (*SinkResult, error)
   728→}
   729→
   730→// SinkOptions configures the sink
   731→type SinkOptions struct {
   732→    // Output location
   733→    OutputPath   string
   734→    OutputFormat OutputFormat
   735→
   736→    // Parquet settings
   737→    Compression    string // snappy, zstd, gzip, lz4, none
   738→    RowGroupSize   int
   739→    PageSize       int
   740→    UseDictionary  bool
   741→
   742→    // Partitioning
   743→    PartitionBy    []string
   744→    PartitionStyle PartitionStyle // hive, directory
   745→
   746→    // File sizing
   747→    TargetFileSize int64 // Target size per file
   748→    MaxRecordsPerFile int64
   749→}
   750→
   751→// SinkResult contains write statistics
   752→type SinkResult struct {
   753→    RowsWritten   int64
   754→    BytesWritten  int64
   755→    FilesWritten  int
   756→    Paths         []string
   757→    Duration      time.Duration
   758→    Checksum      uint64
   759→}
   760→
   761→// OutputFormat for the sink
   762→type OutputFormat string
   763→
   764→const (
   765→    OutputParquet OutputFormat = "parquet"
   766→    OutputIceberg OutputFormat = "iceberg"
   767→    OutputDelta   OutputFormat = "delta"
   768→)
   769→```
   770→
   771→---
   772→
   773→## Quality Requirements
   774→
   775→### Performance Targets
   776→- Clean CSV ingestion: **>900,000 rows/sec**
   777→- Parquet output: **>100 MB/sec**
   778→- Query latency (1M rows): **<100ms**
   779→- Memory usage: **<2x input size** for streaming
   780→
   781→### Reliability Targets
   782→- Data integrity: **100%** (checksums match)
   783→- Error recovery: **>99.9%** rows recovered in permissive mode
   784→- No data loss in quarantine mode
   785→
   786→### Code Quality
   787→- Test coverage: **>80%**
   788→- All public APIs documented
   789→- No panics in production code (recover and return errors)
   790→- Context cancellation respected everywhere
   791→- Resources properly closed (use defer)
   792→
   793→---
   794→
   795→## Implementation Order
   796→
   797→### Phase 1: Foundation (Week 1)
   798→1. `interfaces/` - All interface definitions
   799→2. `ingest/core/` - Source, Decoder, Sink abstractions
   800→3. `defaults/` - Noop implementations
   801→
   802→### Phase 2: Detection & Decoding (Week 2)
   803→4. `ingest/detect/` - Format detection (refactor existing)
   804→5. `ingest/decoders/registry.go` - Decoder registry
   805→6. `ingest/decoders/csv.go` - CSV decoder
   806→7. `ingest/decoders/duckdb.go` - DuckDB decoder (refactor existing)
   807→
   808→### Phase 3: Quality & Flow (Week 3)
   809→8. `ingest/quality/` - Quality validation (refactor existing)
   810→9. `ingest/errors/` - Error handling
   811→10. `ingest/flow/` - Backpressure and concurrency
   812→11. `ingest/heuristics/` - Heuristic engine (refactor existing)
   813→
   814→### Phase 4: Storage (Week 4)
   815→12. `ingest/sinks/parquet.go` - Parquet sink
   816→13. `storage/catalog/file.go` - File-based catalog
   817→14. `storage/object/local.go` - Local filesystem
   818→15. `storage/table/` - Table abstraction
   819→
   820→### Phase 5: Query (Week 5)
   821→16. `query/engine/` - DuckDB query engine
   822→17. `query/sql/` - SQL parsing
   823→18. `query/cache/` - Result caching
   824→
   825→### Phase 6: API & Polish (Week 6)
   826→19. `api/rest/` - REST API
   827→20. `config/` - Configuration
   828→21. `testing/` - Test utilities
   829→22. Documentation and examples
   830→
   831→---
   832→
   833→## Testing Strategy
   834→
   835→### Unit Tests
   836→- Every public function has tests
   837→- Edge cases covered (empty input, huge input, malformed data)
   838→- Mock interfaces for isolation
   839→
   840→### Integration Tests
   841→- Full pipeline tests (ingest → storage → query)
   842→- Multiple formats tested
   843→- Error scenarios tested
   844→
   845→### Benchmark Tests
   846→- Performance regression tests
   847→- Memory usage tests
   848→- Comparison with baseline
   849→
   850→### Fuzz Tests
   851→- All decoders fuzz tested
   852→- No panics on malformed input
   853→
   854→---
   855→
   856→## Example Usage (Target API)
   857→
   858→```go
   859→package main
   860→
   861→import (
   862→    "context"
   863→    "log"
   864→
   865→    "github.com/logflow/logflow"
   866→    "github.com/logflow/logflow/interfaces"
   867→)
   868→
   869→func main() {
   870→    ctx := context.Background()
   871→
   872→    // Simplest: Just convert a file
   873→    result, err := logflow.Convert(ctx, "data.csv", "data.parquet")
   874→    if err != nil {
   875→        log.Fatal(err)
   876→    }
   877→    log.Printf("Converted %d rows", result.RowsWritten)
   878→
   879→    // With options
   880→    result, err = logflow.Convert(ctx, "data.csv", "data.parquet",
   881→        logflow.WithCompression("zstd"),
   882→        logflow.WithQualityValidation(true),
   883→        logflow.WithErrorPolicy(logflow.ErrorPolicyPermissive),
   884→    )
   885→
   886→    // With query
   887→    engine := logflow.NewEngine()
   888→    defer engine.Close()
   889→
   890→    // Ingest
   891→    engine.Ingest(ctx, "events.csv", "events")
   892→
   893→    // Query
   894→    results, err := engine.Query(ctx, `
   895→        SELECT activity, COUNT(*) as count
   896→        FROM events
   897→        GROUP BY activity
   898→        ORDER BY count DESC
   899→    `)
   900→
   901→    // With your own auth
   902→    engine = logflow.NewEngine(
   903→        logflow.WithAuthenticator(myAuthSystem),
   904→        logflow.WithAuthorizer(myRBACSystem),
   905→    )
   906→
   907→    // With catalog (Iceberg tables)
   908→    engine = logflow.NewEngine(
   909→        logflow.WithCatalog(icebergCatalog),
   910→        logflow.WithStorage(s3Storage),
   911→    )
   912→
   913→    // Stream to table
   914→    engine.IngestToTable(ctx, "events.csv", "analytics.events",
   915→        logflow.WithPartitionBy("date"),
   916→    )
   917→}
   918→```
   919→
   920→---
   921→
   922→## Do NOT Do
   923→
   924→1. **Don't build auth implementation** - only interfaces
   925→2. **Don't build cloud storage** - only interfaces (local filesystem default)
   926→3. **Don't build Airflow/Temporal integration** - only scheduler interface
   927→4. **Don't build web UI** - focus on library/API
   928→5. **Don't over-abstract** - keep it simple, add complexity only when needed
   929→6. **Don't break existing functionality** - refactor incrementally
   930→
   931→---
   932→
   933→## Success Criteria
   934→
   935→The library is complete when:
   936→
   937→1. ✅ Can ingest CSV, JSON, JSONL, Parquet, XES with single function call
   938→2. ✅ Outputs valid, queryable Parquet files
   939→3. ✅ Maintains >900K rows/sec for clean CSV
   940→4. ✅ Handles dirty data with configurable error policies
   941→5. ✅ Query engine returns correct results
   942→6. ✅ All interfaces allow extension
   943→7. ✅ Tests pass with >80% coverage
   944→8. ✅ Documentation complete
   945→
   946→---
   947→
   948→## Start Command
   949→
   950→Begin by creating the `interfaces/` package with all interface definitions. This is the foundation everything else builds on.
   951→
   952→```bash
   953→mkdir -p pkg/interfaces
   954→# Create auth.go, catalog.go, storage.go, scheduler.go, metrics.go
   955→```
   956→
   957→Then create `ingest/core/` with Source, Decoder, Sink.
   958→
   959→Then refactor existing code into the new structure.
   960→
   961→**Quality over speed. Get the abstractions right first.**
   962→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
